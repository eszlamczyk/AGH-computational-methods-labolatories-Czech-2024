{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labolatorium 7\n",
    "## Dekompozycja spektralna\n",
    "\n",
    "Oh boy, back to algebra\n",
    "\n",
    "### Wstęp teoretyczny\n",
    "\n",
    "Co jak co przydałby się.\n",
    "\n",
    "Dekompozycja spektralna jest to specjalny przypadek `Dekompozycji na wektory własne` [(ang. Eigendecomposition of a matrix) tak jak nazwa angielska wskazuje jest to podział macierzy (kwadratowej) do postaci kanonicznej, czyli reprezentowanej przez jej `wektory i wartości własne`, więcej [tu](https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix)], w której macierz faktoryzowana jest [normalna](https://en.wikipedia.org/wiki/Normal_matrix), lub [symetryczna](https://en.wikipedia.org/wiki/Symmetric_matrix). Terminologia ta wywodzi się z Twierdzenia spektralnego (dlaczego to jest twierdzeniem po polsku kiedy po angielsku to tylko teoria wiedzą tylko najwięksi matematycy)\n",
    "\n",
    "### 1. Metoda potęgowa\n",
    "\n",
    "[nawet znalazłem coś na wikipedii, nie tylko na wykładzie z macierzowych xd](https://en.wikipedia.org/wiki/Power_iteration)\n",
    "\n",
    "Metoda potęgowa ma na celu wyznaczenie dominującej wartości (i wektora) własnej (czyli najbardziej oddalonej od zera, podobny koncept co przy `Singular Value Decomposition`).\n",
    "\n",
    "Do wyliczenia będziemy stosować wzór rekurencyjny\n",
    "\n",
    "$$\n",
    "x_{i+1} = \\frac{Ax_i}{||x_i||}\n",
    "$$\n",
    "\n",
    "Zapis ten oznacza mnożenie wektora $x_i$ przez macierz A a następnie normalizowanie go po każdym kroku\n",
    "\n",
    "Proces ten wykonujemy aż do przekroczenia maksymalnej liczby iteracji lub w przypadku przekroczenia kryterium małej poprawki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "\n",
    "def normalise_vector(x):\n",
    "    length = calculate_vector_length(x)\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        x[i] /= length\n",
    "\n",
    "def calculate_vector_length(x):\n",
    "    length = 0\n",
    "    for xi in x:\n",
    "        length += xi**2\n",
    "\n",
    "    return math.sqrt(length)\n",
    "\n",
    "def determine_vector_lenght(x1,x2):\n",
    "    sumVec = []\n",
    "    for i in range(len(x1)):\n",
    "        sumVec.append(x1[i]-x2[i])\n",
    "    \n",
    "    return calculate_vector_length(sumVec) \n",
    "\n",
    "def power_method(matrix, max_iter=10000000, eps=1e-30):\n",
    "    \n",
    "    x = np.random.rand(matrix.shape[1])\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        prev_x = deepcopy(x)\n",
    "        x = matrix.dot(x)\n",
    "        normalise_vector(x)\n",
    "        #kryterium małej poprawki\n",
    "        if abs(determine_vector_lenght(prev_x,x)) < eps:\n",
    "            return x , max(x, key=lambda x: abs(x))\n",
    "        \n",
    "    return x , max(x, key=lambda x: abs(x)) \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
